{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twins Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, code is provided for the Twin Study example presented in the paper \"A Fisher Scoring approach for crossed multiple-factor Linear Mixed Models\". The data used in this example was taken from the Wu-Minn Human Connectome project [(Van Essen et al. (2013))](https://pubmed.ncbi.nlm.nih.gov/23684880/) and is not freely available. To obtain the data, see the [Wu-Minn HCP cohort website](https://www.humanconnectome.org/study/hcp-young-adult/document/wu-minn-hcp-consortium-open-access-data-use-terms). Further detail on preprocessing is provided below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package imports\n",
    "import numpy as np\n",
    "import scipy\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Import modules from elsewhere in the repository.\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(os.path.join(module_path,\"src\",\"TwinExample\"))\n",
    "    sys.path.append(os.path.join(module_path,\"src\",\"lib\"))\n",
    "    \n",
    "from genTestDat import genTestData2D, prodMats2D\n",
    "from est2d import *\n",
    "from npMatrix2d import *\n",
    "from ACE import *\n",
    "from scipy.optimize import minimize\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, the data for this example must be obtained from [Wu-Minn HCP cohort website](https://www.humanconnectome.org/study/hcp-young-adult/document/wu-minn-hcp-consortium-open-access-data-use-terms). Once the application process has been completed, access will be granted to $2$ files; the unrestricted (non-sensitive) data and the restricted (sensitive) data. Due to the regulation surrounding these files, we cannot provide either here. To run the following code, please first apply for access to the data and download the data. \n",
    "\n",
    "To begin we first preprocess the data using the Matlab function `hcp2blocks.m` and the below Matlab code. This code is borrowed from the work of [Winkler A. et al (2015)](https://www.sciencedirect.com/science/article/pii/S105381191500508X) and the `hcp2blocks.m` function can be found in the ``src/TwinExample`` folder in this repository. This is the only time Matlab code is used in this work. The below code sorts family units by family structure type and saves the result in the filepath given by the variable `outputfile`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "% Add the path to the `hcp2blocks` function.\n",
    "addpath(% Enter path here...)\n",
    "\n",
    "% Add the path to the restricted data file here.\n",
    "restrfile = % Enter restricted data path here...\n",
    "\n",
    "% The below path describes where some of the output of the function will be saved. We don't actually\n",
    "% use this file so enter any path you like here and feel free to delete this file after the function\n",
    "% has been run.\n",
    "blocksfile = % Enter a name for the csv file that will be output...\n",
    "\n",
    "\n",
    "% Run the hcp2blocks function\n",
    "[EB,tabout] = hcp2blocks(restrfile,blocksfile,true,[],true)\n",
    "\n",
    "% We now name the columns in the tabout table.\n",
    "cHeader = {'Subject' 'Mother_ID' 'Father_ID' 'sibtype','familyID', 'familyType', 'ignore'}; \n",
    "commaHeader = [cHeader;repmat({','},1,numel(cHeader))]; %insert commaas\n",
    "commaHeader = commaHeader(:)';\n",
    "textHeader = cell2mat(commaHeader); %cHeader in text with commas\n",
    "\n",
    "% Specify an output file for the new table\n",
    "outputfile = # Path to family type table...\n",
    "\n",
    "% Write the header column headers to the file\n",
    "fid = fopen(outputfile,'w'); \n",
    "fprintf(fid,'%s\\n',textHeader)\n",
    "fclose(fid)\n",
    "\n",
    "%write data to end of file\n",
    "dlmwrite(outputfile,tabout,'-append','precision',8);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the above code, you should now have $3$ files that are used throughout the rest of this notebook. These are:\n",
    "\n",
    " - The unrestricted data file (downloaded from HCP)\n",
    " - The restricted data file (downloaded from HCP)\n",
    " - The family type file (created by the above Matlab code as `outputfile`)\n",
    " \n",
    "Each of these must now be loaded into memory below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the unrestricted data file\n",
    "unrestricted = pd.read_csv(# Path to unrestricted data file...)\n",
    "\n",
    "# Read in the restricted data file\n",
    "restricted = pd.read_csv(# Path to restricted data file...)\n",
    "\n",
    "# Read in family type data\n",
    "famTypewoDZ = pd.read_csv(# Path to family type file...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now reduce the data to only the variables we need and combine all variables into one table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns not of interest from the family type data.\n",
    "reducedData = famTypewoDZ[['Subject','familyType','familyID']].sort_values(by=['familyType','familyID'])\n",
    "\n",
    "# Reduce the restricted dataset to the variables we need\n",
    "reducedRestricted = restricted[['Subject','Age_in_Yrs','HasGT','ZygosityGT','ZygositySR', 'Family_ID','Mother_ID','Father_ID']]\n",
    "\n",
    "# Make a working table\n",
    "newTab = pd.merge(reducedData, reducedRestricted, on='Subject')\n",
    "\n",
    "# Get a table where every pair of parents has a corresponding count/number of children\n",
    "parentTable = newTab.groupby(['Mother_ID','Father_ID']).size().sort_values(ascending=True).reset_index().rename(columns={0:'ParentCounts'})\n",
    "\n",
    "# Add the parent counts to the new table\n",
    "newTab = pd.merge(newTab,parentTable,on=['Mother_ID','Father_ID'])\n",
    "\n",
    "# Reduce the unrestricted dataset to the variables we need\n",
    "reducedUnrestricted = unrestricted[['Subject','Gender','ReadEng_Unadj','PSQI_Score']]\n",
    "\n",
    "# Add the unrestricted data to our table and drop na values\n",
    "newTab = pd.merge(newTab,reducedUnrestricted,on=['Subject']).dropna()\n",
    "\n",
    "# Recode the gender variable to 0 and 1.\n",
    "newTab['Gender']=newTab['Gender'].replace(['F','M'],[0,1])\n",
    "\n",
    "# Add age and sex interaction\n",
    "newTab['Age:Sex']=newTab[['Age_in_Yrs']].values*newTab[['Gender']].values\n",
    "\n",
    "# Apply the appropriate sort\n",
    "newTab=newTab.sort_values(by=['familyType','familyID','ParentCounts','ZygosityGT','ZygositySR'],ascending=[True,True,False,True,False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check family types have been encoded correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `MATLAB` code mentioned above was designed to calculate the family type for all family units in the HCP dataset (i.e. it categorizes family units by the number of siblings and types of siblings they contain). However, when we decide which variables we wish to use, subjects with missing entries for those variables are dropped from the analysis. This means that some family units may now be ``a person short``. For this reason, the below code has been written to loop through all family units and check they have been assigned to the correct family type. If not it assigns them a new family type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work out the unique types of family\n",
    "UniqueFamilyTypes, idx = np.unique(newTab[['familyType']], return_index=True)\n",
    "UniqueFamilyTypes = UniqueFamilyTypes[np.argsort(idx)]\n",
    "\n",
    "# Number of grouping factors r\n",
    "r = len(UniqueFamilyTypes)\n",
    "\n",
    "# Loop through each family type (these are our factors)\n",
    "for k in np.arange(r):\n",
    "\n",
    "    # Work out which family type we're looking at\n",
    "    uniqueType = UniqueFamilyTypes[k]\n",
    "\n",
    "    # Get the table of these families\n",
    "    familyTypeTable = newTab[newTab['familyType']==uniqueType]\n",
    "\n",
    "    # Get a list of all family IDs in this category\n",
    "    uniqueFamilyIDs = np.unique(familyTypeTable[['familyID']])\n",
    "\n",
    "    # Loop through each family and work out the number of family members\n",
    "    noFamMem = 0\n",
    "    for j in np.arange(len(uniqueFamilyIDs)):\n",
    "\n",
    "        # Get the ID for this family\n",
    "        famID = uniqueFamilyIDs[j]\n",
    "\n",
    "        # Get the table for this ID\n",
    "        famTable = familyTypeTable[familyTypeTable['familyID']==famID]\n",
    "\n",
    "        # Work out the number of subjects in this family\n",
    "        noFamMem = np.maximum(noFamMem, famTable.shape[0])\n",
    "\n",
    "    # Loop through each family and check they have all family members\n",
    "    for j in np.arange(len(uniqueFamilyIDs)):\n",
    "\n",
    "        # Get the ID for this family\n",
    "        famID = uniqueFamilyIDs[j]\n",
    "\n",
    "        # Get the table for this ID\n",
    "        famTable = familyTypeTable[familyTypeTable['familyID']==famID]\n",
    "\n",
    "        # If we don't have all subjects drop this family (we could recalculate\n",
    "        # the family indexes... but this is only an illustrative example).\n",
    "        if noFamMem > famTable.shape[0]:\n",
    "\n",
    "            # Drop the familys that are now missing subjects.\n",
    "            #newTab = newTab.drop(newTab[newTab.familyID == famID].index)\n",
    "\n",
    "            newTab['familyType'][newTab.familyID == famID] = np.amax(UniqueFamilyTypes)+1\n",
    "            UniqueFamilyTypes = np.append(UniqueFamilyTypes,np.amax(UniqueFamilyTypes)+1)\n",
    "\n",
    "# Recalculate the unique types of family\n",
    "UniqueFamilyTypes, idx = np.unique(newTab[['familyType']], return_index=True)\n",
    "UniqueFamilyTypes = UniqueFamilyTypes[np.argsort(idx)]\n",
    "\n",
    "# Recalculate number of grouping factors r\n",
    "r = len(UniqueFamilyTypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables representing the LMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now must construct $X$ and $Y$ for the LMM of the form $Y=X\\beta+Zb+\\epsilon$. $Z$ does not need to be constructed as, for the Twin dataset, $Z$ is just the identity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct X\n",
    "X = newTab[['Age_in_Yrs','Gender','Age:Sex','PSQI_Score']].values \n",
    "\n",
    "# Add an intercept to X\n",
    "X = np.concatenate((np.ones((X.shape[0],1)),X),axis=1)\n",
    "\n",
    "# Construct Y\n",
    "Y = newTab[['ReadEng_Unadj']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below scalar variables will be useful later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of fixed effects parameters p\n",
    "p = X.shape[1]\n",
    "\n",
    "# Number of observations\n",
    "n = X.shape[0]\n",
    "\n",
    "# Convergence tolerance\n",
    "tol = 1e-6\n",
    "\n",
    "# Set ReML\n",
    "reml=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Kinship matrices and random effects variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below code the random effects variables $\\{l_k\\}_{k\\in\\{1,...,r\\}}$ (i.e. `nlevels` in the code) and $\\{q_k\\}_{k\\in\\{1,...,r\\}}$  (i.e. `nraneffs` in the code) are calculated. Also calculated are the Kinship matrices, $\\{\\mathbf{K}^a_k\\}_{k\\in\\{1,...,r\\}}$ and $\\{\\mathbf{K}^c_k\\}_{k\\in\\{1,...,r\\}}$ (see Appendix 6.7 of \"A Fisher Scoring approach for crossed multiple-factor Linear Mixed Models\" for more information on Kinship matrices)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of levels and random effects for each factor\n",
    "nlevels = np.zeros(r)\n",
    "nraneffs = np.zeros(r)\n",
    "\n",
    "# Dictionary to store Kinship matrices\n",
    "KinshipA = dict()\n",
    "KinshipC = dict()\n",
    "\n",
    "# Loop through each family type (these are our factors)\n",
    "for k in np.arange(r):\n",
    "\n",
    "    # Record the family structure, if we haven't already.\n",
    "    if k not in KinshipA:\n",
    "\n",
    "        # Work out which family type we're looking at\n",
    "        uniqueType = UniqueFamilyTypes[k]\n",
    "        familyTypeTable = newTab[newTab['familyType']==uniqueType]\n",
    "\n",
    "        # Read in the first family in this category\n",
    "        uniqueFamilyIDs = np.unique(familyTypeTable[['familyID']])\n",
    "        famID = uniqueFamilyIDs[0]\n",
    "        famTable = familyTypeTable[familyTypeTable['familyID']==famID]\n",
    "\n",
    "        # Work out how many subjects in family\n",
    "        numSubs = len(famTable)\n",
    "\n",
    "        # Initialize empty K_A and fill K_C with ones\n",
    "        KinshipA[k] = np.zeros((numSubs,numSubs))\n",
    "        KinshipC[k] = np.ones((numSubs,numSubs))\n",
    "\n",
    "        # Loop through each pair of subjects (the families are very \n",
    "        # small in the HCP dataset so it doesn't matter if this\n",
    "        # code is a little inefficient)\n",
    "        for i in np.arange(numSubs):\n",
    "            for j in np.arange(numSubs):\n",
    "                # Check if subject i and subject j are the same person\n",
    "                if i==j:\n",
    "                    # In this case cov_A(i,j)=1\n",
    "                    KinshipA[k][i,j]=1\n",
    "\n",
    "                # Check if subject i and subject j are the MZ twins\n",
    "                elif (famTable['ZygosityGT'].iloc[i]=='MZ' or famTable['ZygositySR'].iloc[i]=='MZ') and (famTable['ZygosityGT'].iloc[j]=='MZ' or famTable['ZygositySR'].iloc[j]=='MZ'):\n",
    "                    # In this case cov_A(i,j)=1\n",
    "                    KinshipA[k][i,j]=1\n",
    "\n",
    "                # Check if subject i and subject j are full siblings (DZ is grouped into this usecase)\n",
    "                elif (famTable['Mother_ID'].iloc[i]==famTable['Mother_ID'].iloc[j] and famTable['Father_ID'].iloc[i]==famTable['Father_ID'].iloc[j]):\n",
    "\n",
    "                    # In this case cov_A(i,j)=1/2\n",
    "                    KinshipA[k][i,j]=1/2\n",
    "\n",
    "                # Check if subject i and subject j are half siblings\n",
    "                elif (famTable['Mother_ID'].iloc[i]==famTable['Mother_ID'].iloc[j] or famTable['Father_ID'].iloc[i]==famTable['Father_ID'].iloc[j]):\n",
    "\n",
    "                    # In this case cov_A(i,j)=1/2\n",
    "                    KinshipA[k][i,j]=1/4\n",
    "\n",
    "                # Else they aren't related\n",
    "                else:\n",
    "\n",
    "                    # In this case cov_A(i,j)=0\n",
    "                    KinshipA[k][i,j]=0\n",
    "\n",
    "        # Work out nlevels\n",
    "        nlevels[k]=len(uniqueFamilyIDs)\n",
    "        \n",
    "        # Work out nraneffs\n",
    "        nraneffs[k]=numSubs\n",
    "\n",
    "# Change to ints\n",
    "nlevels = np.array(nlevels, dtype=np.int32)\n",
    "nraneffs = np.array(nraneffs, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below variables are useful for calculation. The $q$ variable matches that in the paper and is the second dimension of the $Z$ matrix. The `Dinds` variable is an array containing the indices corresponding to the first member of every family unit in the random effects design matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second dimension of Z matrix, q\n",
    "q = np.sum(np.dot(nraneffs,nlevels))\n",
    "\n",
    "# Work out D indices (there is one block of D per level)\n",
    "Dinds = np.zeros(np.sum(nlevels)+1)\n",
    "counter = 0\n",
    "for k in np.arange(len(nraneffs)):\n",
    "    for j in np.arange(nlevels[k]):\n",
    "        Dinds[counter] = np.concatenate((np.array([0]), np.cumsum(nlevels*nraneffs)))[k] + nraneffs[k]*j\n",
    "        counter = counter + 1\n",
    "\n",
    "# Last index will be missing so add it\n",
    "Dinds[len(Dinds)-1]=Dinds[len(Dinds)-2]+nraneffs[-1]\n",
    "\n",
    "# Make sure indices are ints\n",
    "Dinds = np.int64(Dinds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constraint matrix calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code, much like in the proofs of Appendix 6.7.2, we seperate the calculation of the constraint matrix $\\mathcal{C}$ into two parts; \n",
    " - The constraint matrices mapping $\\text{vec}(D_k)$ to $[\\tilde{\\tau}_{a,k},\\tilde{\\tau}_{c,k}]'$\n",
    " - The constraint matrices mapping $\\tilde{\\tau}=[\\tilde{\\tau}_{a,1},\\tilde{\\tau}_{c,1}, ..., \\tilde{\\tau}_{a,r},\\tilde{\\tau}_{c,r}]'$ to $\\tau=[\\tau_a,\\tau_c]$.\n",
    " \n",
    "In the code the former is referred to as the constraint matrix of the first kind and the latter referred to as the constraint matrix of the second kind (this terminology was only invented to keep track of this part of the code and is not used elsewhere)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create constraint matrices of the first kind for mapping D_k to \\sigma2_A and \\sigma2_C\n",
    "constrMat1stDict = dict()\n",
    "\n",
    "# Loop through each family type and get the constraint matrix\n",
    "for k in np.arange(r):\n",
    "    \n",
    "    # Row of constraint matrix k describing \\sigmaA\n",
    "    SkrowA = mat2vec2D(KinshipA[k]).transpose()\n",
    "    \n",
    "    # Row of constraint matrix k describing \\sigmaC\n",
    "    SkrowC = mat2vec2D(KinshipC[k]).transpose()\n",
    "\n",
    "    # Construct constraint matrices\n",
    "    constrMat1stDict[k]=np.concatenate((SkrowA,SkrowC),axis=0)\n",
    "\n",
    "# Work out constraint matrix of the second kind\n",
    "constrMat2nd = np.concatenate((np.tile([[1,0]],r),np.tile([[0,1]],r)),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate $\\sum X_{(k,j)}' \\otimes X_{(k,j)}'$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is only used for speeding up the Powell optimizer to ensure fair comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work out sum over j of X_(k,j) kron X_(k,j), for each k\n",
    "XkXdict = dict()\n",
    "\n",
    "# Loop through levels and factors\n",
    "for k in np.arange(r):\n",
    "\n",
    "    # Get qk\n",
    "    qk = nraneffs[k]\n",
    "\n",
    "    # Sum XkX\n",
    "    XkXdict[k] = np.zeros((p**2,qk**2))\n",
    "\n",
    "    for j in np.arange(nlevels[k]):\n",
    "\n",
    "        # Indices for level j of factor k\n",
    "        Ikj = faclev_indices2D(k, j, nlevels, nraneffs)\n",
    "\n",
    "        # Add to running sum\n",
    "        XkXdict[k] = XkXdict[k] + np.kron(X[Ikj,:].transpose(),X[Ikj,:].transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below functions calculates the log likelihood of the ACE model given an estimate of the parameters of the model, alongside the variables we have calculated above. This is the function which shall be maximized by the Powell Optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llh_ACE(paramVec, X, Y, n, p, nlevels, nraneffs, Dinds, KinshipA, KinshipC, reml=False, XkXdict=None):\n",
    "\n",
    "    # Reshape to 2D\n",
    "    paramVec = paramVec.reshape(p+3,1)\n",
    "\n",
    "    # Get current parameter estimates\n",
    "    beta = paramVec[0:p,:]\n",
    "    sigma2 = paramVec[p,:][0]**2\n",
    "    tau2 = paramVec[(p+1):,:]**2\n",
    "\n",
    "    # Obtain residual vector\n",
    "    e = Y - X @ beta\n",
    "\n",
    "    # Inital D (dict version)\n",
    "    Ddict = dict()\n",
    "    for k in np.arange(len(nraneffs)):\n",
    "        # Construct D using sigma^2A and sigma^2D\n",
    "        Ddict[k] = forceSym2D(tau2[0,0]*KinshipA[k] + tau2[1,0]*KinshipC[k])\n",
    "\n",
    "    # ------------------------------------------------------------------------------\n",
    "    # Obtain (I+D)^{-1}\n",
    "    # ------------------------------------------------------------------------------\n",
    "    invIplusDdict = dict()\n",
    "    for k in np.arange(len(nraneffs)):\n",
    "        # Construct D using sigma^2A and sigma^2D\n",
    "        invIplusDdict[k] = forceSym2D(np.linalg.pinv(np.eye(nraneffs[k])+Ddict[k]))\n",
    "\n",
    "\n",
    "    # (D+I)^{-1} (matrix version)\n",
    "    invIplusD = scipy.sparse.lil_matrix((n,n))\n",
    "    counter = 0\n",
    "    for k in np.arange(len(nraneffs)):\n",
    "        for j in np.arange(nlevels[k]):\n",
    "\n",
    "            # Add a block for each level of each factor.\n",
    "            invIplusD[Dinds[counter]:Dinds[counter+1], Dinds[counter]:Dinds[counter+1]] = invIplusDdict[k]\n",
    "            counter = counter + 1\n",
    "\n",
    "    # Update e'V^(-1)e\n",
    "    etinvVe = e.transpose() @ invIplusD @ e\n",
    "\n",
    "    # Work out log|V| using the fact V is block diagonal\n",
    "    logdetV = 0\n",
    "    for k in np.arange(len(nraneffs)):\n",
    "        logdetV = logdetV - nlevels[k]*np.log(np.linalg.det(invIplusDdict[k]))\n",
    "\n",
    "    # Work out the log likelihood\n",
    "    llhcurr = 0.5*(n*np.log(sigma2)+(1/sigma2)*etinvVe + logdetV)\n",
    "\n",
    "    if reml:\n",
    "\n",
    "        # Work out X'V^(-1)X as matrix reshape of (sum over k of ((sum_j X_(k,j) kron X_(k,j))vec(D_k)))\n",
    "        XtinvVX = np.zeros((p,p))\n",
    "\n",
    "        # Loop through levels and factors\n",
    "        for k in np.arange(r):\n",
    "\n",
    "            XtinvVX = XtinvVX + vec2mat2D(XkXdict[k] @ mat2vec2D(invIplusDdict[k]),shape=np.array([p,p]))\n",
    "\n",
    "        logdet = np.linalg.slogdet(XtinvVX)\n",
    "        llhcurr = llhcurr - 0.5*logdet[0]*logdet[1] + 0.5*p*np.log(sigma2)\n",
    "\n",
    "    return(llhcurr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below function calculates the standard error of $\\hat{\\beta}$ for the ACE model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seBeta_ACE(paramVec, p, KinshipA, KinshipC, nlevels, nraneffs):\n",
    "\n",
    "    # Work out beta, sigma2 and the vector of variance components\n",
    "    beta = paramVec[0:p,:]\n",
    "    sigma2 = paramVec[p,0]**2\n",
    "    tau2 = paramVec[(p+1):,:]**2/sigma2\n",
    "\n",
    "    # Get D in dictionary form\n",
    "    Ddict = dict()\n",
    "    for k in np.arange(len(nraneffs)):\n",
    "        # Construct D using sigma^2A and sigma^2D\n",
    "        Ddict[k] = tau2[0,0]*KinshipA[k] + tau2[1,0]*KinshipC[k]\n",
    "\n",
    "    # r, total number of random factors\n",
    "    r = len(nlevels)\n",
    "\n",
    "    # Work out sum over j of X_(k,j) kron X_(k,j), for each k\n",
    "    XkXdict = dict()\n",
    "\n",
    "    # Loop through levels and factors\n",
    "    for k in np.arange(r):\n",
    "\n",
    "        # Get qk\n",
    "        qk = nraneffs[k]\n",
    "\n",
    "        # Sum XkX\n",
    "        XkXdict[k] = np.zeros((p**2,qk**2))\n",
    "\n",
    "        for j in np.arange(nlevels[k]):\n",
    "\n",
    "            # Indices for level j of factor k\n",
    "            Ikj = faclev_indices2D(k, j, nlevels, nraneffs)\n",
    "\n",
    "            # Add to running sum\n",
    "            XkXdict[k] = XkXdict[k] + np.kron(X[Ikj,:].transpose(),X[Ikj,:].transpose())\n",
    "\n",
    "            \n",
    "    # Work out X'V^(-1)X as matrix reshape of (sum over k of ((sum_j X_(k,j) kron X_(k,j))vec(D_k)))\n",
    "    XtinvVX = np.zeros((p,p))\n",
    "\n",
    "    # Loop through levels and factors\n",
    "    for k in np.arange(r):\n",
    "\n",
    "        XtinvVX = XtinvVX + vec2mat2D(XkXdict[k] @ mat2vec2D(np.linalg.pinv(np.eye(nraneffs[k])+Ddict[k])),shape=np.array([p,p]))\n",
    "\n",
    "\n",
    "    # Get variance of beta\n",
    "    varb = sigma2*np.linalg.inv(XtinvVX)\n",
    "\n",
    "    return(np.sqrt(np.diagonal(varb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code generates some initial estimates of $\\beta$, $\\sigma^2$ and $\\tau$. These shall be used later on by the Powell optimizer only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Product matrices (only used here)\n",
    "# ------------------------------------------------------------------------------\n",
    "XtX = X.transpose() @ X\n",
    "XtY = X.transpose() @ Y\n",
    "YtY = Y.transpose() @ Y\n",
    "YtX = Y.transpose() @ X\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Initial estimates\n",
    "# ------------------------------------------------------------------------------\n",
    "# If we have initial estimates use them.\n",
    "\n",
    "# Inital beta\n",
    "beta = initBeta2D(XtX, XtY)\n",
    "\n",
    "# Work out e'e\n",
    "ete = ssr2D(YtX, YtY, XtX, beta)\n",
    "\n",
    "# Initial sigma2\n",
    "sigma2 = initSigma22D(ete, n)\n",
    "sigma2 = np.maximum(sigma2,1e-10) # Prevent hitting boundary\n",
    "sigma2 = np.array([[sigma2]])\n",
    "\n",
    "# Initial zero matrix to hold the matrices Ckcov(dl/Dk)Ck'\n",
    "FDk = np.zeros((2*r,2*r))\n",
    "\n",
    "# Initial zero vector to hold the vectors Ck*dl/dDk\n",
    "CkdldDk = np.zeros((2*r,1))\n",
    "\n",
    "# Initial residuals\n",
    "e = Y - X @ beta\n",
    "eet = e @ e.transpose()\n",
    "\n",
    "for k in np.arange(r):\n",
    "\n",
    "    # Get FDk\n",
    "    FDk[2*k:(2*k+2),2*k:(2*k+2)]= nlevels[k]*constrMat1stDict[k] @ constrMat1stDict[k].transpose()\n",
    "\n",
    "    # Initialize empty sum\n",
    "    eetSum = np.zeros((nraneffs[k],nraneffs[k]))\n",
    "\n",
    "    # Get sum ee'_[k,j,j]\n",
    "    for j in np.arange(nlevels[k]):\n",
    "\n",
    "        # Get indices for current block\n",
    "        Ikj = faclev_indices2D(k, j, nlevels, nraneffs)\n",
    "\n",
    "        # Add to current sum\n",
    "        eetSum = eetSum + eet[np.ix_(Ikj,Ikj)]\n",
    "\n",
    "    # Get Ck*dl/dDk\n",
    "    CkdldDk[2*k:(2*k+2),:] = constrMat1stDict[k] @ mat2vec2D(nlevels[k]-eetSum/sigma2)\n",
    "\n",
    "\n",
    "# Initial vec(sigma^2A/sigma^2E, sigma^2C/sigma^2E)\n",
    "tau2 = np.linalg.pinv(constrMat2nd @ FDk @ constrMat2nd.transpose()) @ constrMat2nd @ CkdldDk\n",
    "\n",
    "# Initial parameter vector\n",
    "initParams = np.concatenate((beta, sigma2, tau2*sigma2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PFS method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code runs the PFS algorithm and times it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run and time the PFS algorithm\n",
    "t1 = time.time()\n",
    "PFS_out=pFS_ACE2D(X, Y, nlevels, nraneffs, tol, n, KinshipA, KinshipC, constrMat1stDict, constrMat2nd,reml=reml)\n",
    "t2 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the time taken for computation for the PFS method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Computation time: ', t2-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the estimates for the $\\beta$ parameters obtained with the PFS method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the parameter vector\n",
    "paramVecACE = np.array(PFS_out[0])\n",
    "\n",
    "# Convert it to display format\n",
    "toDisplay = np.array(paramVecACE)\n",
    "toDisplay[(p+1):,:] = toDisplay[(p+1):,:]*toDisplay[p,0]\n",
    "\n",
    "# Print beta estimates\n",
    "print('Beta 0 (intercept):  ', toDisplay[0,0])\n",
    "print('Beta 1 (Age):        ', toDisplay[1,0])\n",
    "print('Beta 2 (Sex):        ', toDisplay[2,0])\n",
    "print('Beta 3 (Age:Sex):    ', toDisplay[3,0])\n",
    "print('Beta 4 (PSQI score): ', toDisplay[4,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the estimates for the $\\sigma^2$ parameters obtained with the PFS method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print sigma^2 estimates\n",
    "print('Sigma^2 A (Additive genetic):   ', toDisplay[6,0]**2)\n",
    "print('Sigma^2 C (Common Environment): ', toDisplay[7,0]**2)\n",
    "print('Sigma^2 E (Error):              ', toDisplay[5,0]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the maximized log-likelihood output by the PFS method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('log-likelihood: ', -(llh_ACE(paramVecACE, X, Y, n, p, nlevels, nraneffs, Dinds, KinshipA, KinshipC, reml=reml, XkXdict=XkXdict)[0,0]-n/2*np.log(2*np.pi)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the standard errors for the $\\beta$ estimates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seBeta = seBeta_ACE(toDisplay, p, KinshipA, KinshipC, nlevels, nraneffs)\n",
    "print('Standard Errors for beta estimates: ', seBeta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the results for the T tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrastNames = ['Intercept', 'Age', 'Sex', 'Age:Sex', 'PSQI Score']\n",
    "\n",
    "# Loop through fixed effects parameters\n",
    "for j in np.arange(p):\n",
    "    \n",
    "    print('-----------------------------------------')\n",
    "    print('T test for contrast ' + str(j) + ': ' + contrastNames[j])\n",
    "    print('-----------------------------------------')\n",
    "    \n",
    "    # Create contrast vectors\n",
    "    L = np.zeros((1,p))\n",
    "    L[0,j]=1\n",
    "\n",
    "    # Obtain the satterthwaithe degrees of freedom estimate for the contrast\n",
    "    swdf = get_swdf_ACE_T2D(L, paramVecACE, X, nlevels, nraneffs, KinshipA, KinshipC, constrMat1stDict)\n",
    "    \n",
    "    print('swdf: ', swdf[0,0])\n",
    "    \n",
    "    # Obtain the T statistic for the contrast\n",
    "    T = get_T_ACE_2D(L, X, paramVecACE, KinshipA, KinshipC, nlevels, nraneffs)\n",
    "    print('T: ', T[0,0])\n",
    "    \n",
    "    # Obtain the P value for the T statistic\n",
    "    if T < 0:\n",
    "        pvalACE = 1-stats.t.cdf(T, swdf)\n",
    "    else:\n",
    "        pvalACE = stats.t.cdf(-T, swdf)\n",
    "\n",
    "    # Convert the T test between two tailed and one tailed format.\n",
    "    if pvalACE < 0.5:\n",
    "        pvalACE = 2*pvalACE\n",
    "    else:\n",
    "        pvalACE = 2*(1-pvalACE)\n",
    "\n",
    "    print('P: ', pvalACE[0,0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Powell method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code runs the Powell optimizer and times it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "Powell_out = minimize(llh_ACE, initParams, args=(X, Y, n, p, nlevels, nraneffs, Dinds, KinshipA, KinshipC, reml, XkXdict), method='Powell', tol=1e-6)\n",
    "t2 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the time taken for computation for the Powell method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Computation time: ', t2-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the estimates for the $\\beta$ parameters obtained with the Powell method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the parameter vector\n",
    "paramVecOpt = Powell_out['x'].reshape((p+3),1)\n",
    "\n",
    "# Convert it to display format\n",
    "toDisplay = np.array(paramVecACE)\n",
    "toDisplay[(p+1):,:] = toDisplay[(p+1):,:]*toDisplay[p,0]\n",
    "\n",
    "# Print beta coordinates\n",
    "print('Beta 0 (intercept):  ', toDisplay[0,0])\n",
    "print('Beta 1 (Age):        ', toDisplay[1,0])\n",
    "print('Beta 2 (Sex):        ', toDisplay[2,0])\n",
    "print('Beta 3 (Age:Sex):    ', toDisplay[3,0])\n",
    "print('Beta 4 (PSQI score): ', toDisplay[4,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the estimates for the $\\sigma^2$ parameters obtained with the PFS method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print sigma^2 estimates\n",
    "print('Sigma^2 A (Additive genetic):   ', toDisplay[6,0]**2)\n",
    "print('Sigma^2 C (Common Environment): ', toDisplay[7,0]**2)\n",
    "print('Sigma^2 E (Error):              ', toDisplay[5,0]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the maximized log-likelihood output by the Powell method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(-(np.array([[Powell_out['fun']]])[0,0]-n/2*np.log(2*np.pi)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the standard errors for the $\\beta$ estimates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seBeta = seBeta_ACE(toDisplay, p, KinshipA, KinshipC, nlevels, nraneffs)\n",
    "print('Standard Errors for beta estimates: ', seBeta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the results for the T tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through fixed effects parameters\n",
    "for j in np.arange(p):\n",
    "    \n",
    "    print('-----------------------------------------')\n",
    "    print('T test for contrast ' + str(j) + ': ' + contrastNames[j])\n",
    "    print('-----------------------------------------')\n",
    "    \n",
    "    # Create contrast vectors\n",
    "    L = np.zeros((1,p))\n",
    "    L[0,j]=1\n",
    "    \n",
    "    # Obtain the satterthwaithe degrees of freedom estimate for the contrast\n",
    "    swdf = get_swdf_ACE_T2D(L, paramVecOpt, X, nlevels, nraneffs, KinshipA, KinshipC, constrMat1stDict)\n",
    "    \n",
    "    print('swdf: ', swdf[0,0])\n",
    "    \n",
    "    # Obtain the T statistic for the contrast\n",
    "    T = get_T_ACE_2D(L, X, paramVecOpt, KinshipA, KinshipC, nlevels, nraneffs)\n",
    "    \n",
    "    print('T: ', T[0,0])\n",
    "    \n",
    "    # Obtain the P value for the T statistic\n",
    "    if T < 0:\n",
    "        pvalOpt = 1-stats.t.cdf(T, swdf)\n",
    "    else:\n",
    "        pvalOpt = stats.t.cdf(-T, swdf)\n",
    "\n",
    "    # Convert the T test between two tailed and one tailed format.\n",
    "    if pvalOpt < 0.5:\n",
    "        pvalOpt = 2*pvalOpt\n",
    "    else:\n",
    "        pvalOpt = 2*(1-pvalOpt)\n",
    "\n",
    "    print('P: ', pvalOpt[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code runs OLS and times it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the clock\n",
    "t1 = time.time()\n",
    "\n",
    "# Obtain beta estimates\n",
    "betaOLS = np.linalg.pinv(X.transpose() @ X) @ X.transpose() @ Y\n",
    "\n",
    "# Obtain residual vector\n",
    "e = Y - X @ betaOLS\n",
    "\n",
    "# Obtain sigma_OLS\n",
    "sigmaOLS = np.sqrt(e.transpose() @ e/(n-p))\n",
    "\n",
    "# stop the clock\n",
    "t2 = time.time()\n",
    "\n",
    "# Reformat parameters\n",
    "sigma2OLS = sigmaOLS**2\n",
    "\n",
    "# Construct parameter vector\n",
    "paramVecOLS = np.zeros(((p+3),1))\n",
    "paramVecOLS[0:p,:] = betaOLS\n",
    "paramVecOLS[p,:] = sigmaOLS[0,0]\n",
    "\n",
    "# Display variable\n",
    "toDisplay = np.array(paramVecOLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the time taken for OLS computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Computation time: ', t2-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the estimates for the $\\beta$ parameters obtained with OLS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print beta coordinates\n",
    "print('Beta 0 (intercept):  ', toDisplay[0,0])\n",
    "print('Beta 1 (Age):        ', toDisplay[1,0])\n",
    "print('Beta 2 (Sex):        ', toDisplay[2,0])\n",
    "print('Beta 3 (Age:Sex):    ', toDisplay[3,0])\n",
    "print('Beta 4 (PSQI score): ', toDisplay[4,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the estimates for the $\\sigma^2$ parameters obtained with OLS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print sigma^2 estimates\n",
    "print('Sigma^2 A (Additive genetic):   ', toDisplay[6,0]**2)\n",
    "print('Sigma^2 C (Common Environment): ', toDisplay[7,0]**2)\n",
    "print('Sigma^2 E (Error):              ', toDisplay[5,0]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the maximized log-likelihood output by OLS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(-(llh_ACE(toDisplay, X, Y, n, p, nlevels, nraneffs, Dinds, KinshipA, KinshipC, reml=reml, XkXdict=XkXdict)[0,0]-n/2*np.log(2*np.pi)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the standard errors for the $\\beta$ estimates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seBeta = seBeta_ACE(toDisplay, p, KinshipA, KinshipC, nlevels, nraneffs)\n",
    "print('Standard Errors for beta estimates: ', seBeta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the results for the T tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through fixed effects parameters\n",
    "for i in np.arange(X.shape[1]):\n",
    "    \n",
    "    print('-----------------------------------------')\n",
    "    print('T test for contrast ' + str(j) + ': ' + contrastNames[j])\n",
    "    print('-----------------------------------------')\n",
    "\n",
    "    # Create contrast vectors\n",
    "    L = np.zeros((1,X.shape[1]))\n",
    "    L[0,i]=1\n",
    "\n",
    "    # Obtain the T statistic for the contrast\n",
    "    TOLS = (L @ betaOLS)/ np.sqrt(sigma2OLS*(L @ np.linalg.pinv(XtX) @ L.transpose()))\n",
    "\n",
    "    # Degrees of freedom for OLS\n",
    "    df_OLS = n-p\n",
    "\n",
    "    # Obtain the P value for the T statistic\n",
    "    if T < 0:\n",
    "        pvalOLS = 1-stats.t.cdf(TOLS, df_OLS)\n",
    "    else:\n",
    "        pvalOLS = stats.t.cdf(-TOLS, df_OLS)\n",
    "\n",
    "    # Convert the T test between two tailed and one tailed format.\n",
    "    if pvalOLS < 0.5:\n",
    "        pvalOLS = 2*pvalOLS\n",
    "    else:\n",
    "        pvalOLS = 2*(1-pvalOLS)\n",
    "\n",
    "    print('df: ', df_OLS)\n",
    "    print('T: ', TOLS[0,0])\n",
    "    print('pval: ', pvalOLS[0,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
