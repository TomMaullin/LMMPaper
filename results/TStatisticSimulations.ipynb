{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T-statistic Simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides an overview of how the T-statistic degrees of freedom estimation simulations presented in the paper \"A Fisher Scoring approach for crossed multiple-factor Linear Mixed Models\" were performed using the code available in this repository. \n",
    "\n",
    "As the simulations in the paper were run on a SGE cluster set-up (and the scripts used were specific to the cluster and software employed), we provide details on how to run individual simulations and how to combine the results from simulations which have already been run but do not provide scripts for submitting jobs to a cluster. This notebook should make it clear how the simulations can be run on a cluster but, to do so, you will need to write your own cluster-specific scripts for the actual job submission. The file `src/Simulations/LMMPaperSim.sh` provides some initial bash scripts which may help you to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package imports\n",
    "import numpy as np\n",
    "import scipy\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import sys\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Import modules from elsewhere in the repository.\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(os.path.join(module_path,\"src\",\"Simulations\"))\n",
    "    sys.path.append(os.path.join(module_path,\"src\",\"lib\"))\n",
    "    \n",
    "from genTestDat import genTestData2D, prodMats2D\n",
    "from LMMPaperSim import *\n",
    "from est2d import *\n",
    "from npMatrix2d import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `runSim`, which can be found in `LMMPaperSim.py`, can be used to run a single simulation instance. It takes the following inputs:\n",
    "\n",
    " - `simInd`: An index to represent the simulation. All output for this simulation will be saved in files with the index specified by this argument. The simulation with index 1 will also perform any necessary additional setup and should therefore be run before any others.\n",
    " - `desInd`: Integer value between 1 and 3 representing which design to run. The designs are as follows:\n",
    "   - `Design 1: nlevels=[50], nraneffs=[2]`\n",
    "   - `Design 2: nlevels=[50,10], nraneffs=[3,2]`\n",
    "   - `Design 3: nlevels=[100,50,10], nraneffs=[4,3,2]`\n",
    " - `OutDir`: The output directory.\n",
    " - `mode`: String indicating whether to run parameter estimation simulations (`mode='param'`) or T statistic simulations (`mode='Tstat'`).\n",
    " - `REML`: Boolean indicating whether to use ML or ReML estimation. \n",
    "\n",
    "An example of how this function can be used is given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a simulation with index 1\n",
    "simInd = 1\n",
    "\n",
    "# Use design 2\n",
    "desInd = 2\n",
    "\n",
    "# Set output directory\n",
    "OutDir = os.path.join(module_path,\"data\",\"TstatSimulation\")\n",
    "\n",
    "# Make the output directory if it doesn't exist already.\n",
    "if not os.path.isdir(OutDir):\n",
    "    os.mkdir(OutDir)\n",
    "\n",
    "# Run a simulation\n",
    "runSim(simInd, desInd, OutDir, mode='Tstat', REML=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Due to the comprehensive estimation of the degrees of freedom for the ground truth of these simulations, the above function may take a lot longer to run than its `param` mode counterpart. This was one of the motivating factors in designing the code to be run on a cluster set-up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example output from running one simulation is given below. The files output for the $i^{th}$ simulation running the $j^{th}$ design are as follows:\n",
    "\n",
    "- `Sim{i}_Design{j}_X.csv`: The fixed effects design used for the simulation.\n",
    "- `Sim{i}_Design{j}_Y.csv`: The response vector used for the simulation.\n",
    "- `Sim{i}_Design{j}_Zfactor{k}.csv`: The factor vector for the $k^{th}$ random factor (See Appendix $6.1$ of the main paper for more details).\n",
    "- `Sim{i}_Design{j}_Zdata{k}.csv`: The raw regressor matrix for the $k^{th}$ random factor (See Appendix $6.1$ of the main paper for more details).\n",
    "- `Sim{i}_Design{j}_results.csv`: The results of the simulation.\n",
    "\n",
    "For the first simulation running the $j^{th}$ design the following files are also output:\n",
    "- `fv_{j}_{k}`: The factor vector for the $k^{th}$ random factor (See Appendix $6.1$ of the main paper for more details).\n",
    "- `Z_{j}.csv`: The random effects raw regressor matrix used for the simulation.\n",
    "- `X_{j}.csv`: The fixed effects regressor matrix used for the simulation.\n",
    "\n",
    "These files are output as a sanity check to ensure that $X$ and $Z$ are identical for all simulations. This may seem like overkill but did result in some very obscure bug catching and has been left in for posterity measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List contents of output directory.\n",
    "os.listdir(OutDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below provides a display of what can be found in the 'results' file listed above. The first column provides the ground truth used for this simulation and the other columns provide the results of each Fisher Scoring method. The column indices are: \n",
    "\n",
    " - `Time`: Time (in seconds) taken for computation.\n",
    " - `nit`: Number of iterations performed.\n",
    " - `llh`: Maximised (restricted) Log-likelihood function.\n",
    " - `beta{i}`: The $i^{th}$ fixed effects estimate, $\\beta$.\n",
    " - `sigma2`: The fixed effects variance, $\\sigma^2$.\n",
    " - `D{k},{j}`: The $j^{th}$ estimated component of vech$(D_k)$.\n",
    " - `sigma2*D{k},{j}`: The fixed effects variance, $\\sigma^2$, multiplied by the $j^{th}$ estimated component of vech$(D_k)$ (often any further computation is more concerned with this quantity than the seperate $\\sigma^2$ and $D$ components). \n",
    " - `T`: A T-statistic for the contrast `[0,0,0,0,1]` (i.e. a T-statistic testing for evidence of the only zero-valued fixed effects beta parameter).\n",
    " - `p`: A p-value corresponding to `T`.\n",
    " - `swdf`: The estimated Satterthwaithe degrees of freedom used to calculate the `p` value from the `T` statistic. The value in the truth column corresponds to the simulated ground truth P-value. This was simulated using $1000$ additional simulations in this run*.\n",
    " \n",
    "*Note: In our paper, we reported estimating the ground truth with $1,000,000$ simulations. To avoid any confusion here, we highlight that we ran $1000$ T-statistic simulation jobs, each of which, like the above example, ran a further $1000$ simulations to assess the baseline truth (hence, $1000\\times1000=1,000,000$). All baseline truth estimates are then combined in the final stage of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the results file.\n",
    "results_table = pd.read_csv(os.path.join(OutDir,'Sim1_Design2_results.csv'),index_col=0)\n",
    "\n",
    "# Display results\n",
    "results_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running multiple simulations in serial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many simulations can be run in serial. The function `sim2D` can be used to do this. It takes the following inputs:\n",
    "\n",
    " - `desInd`: Integer value between 1 and 3 representing which design to run. The designs are as follows:\n",
    "   - `Design 1: nlevels=[50], nraneffs=[2]`\n",
    "   - `Design 2: nlevels=[50,10], nraneffs=[3,2]`\n",
    "   - `Design 3: nlevels=[100,50,10], nraneffs=[4,3,2]`\n",
    " - `OutDir`: The output directory.\n",
    " - `nsim`: Number of simulations (default=`1000`)\n",
    " - `mode`: String indicating whether to run parameter estimation simulations (`mode='param'`) or T-statistic simulations (`mode='Tstat'`).\n",
    " - `REML`: Boolean indicating whether to use ML or ReML estimation. \n",
    "\n",
    "An example of how this function can be used is given below: \n",
    "\n",
    "**WARNING:** Each of the T-statistic simulations is running a further $1000$ simulations to establish the degrees of freedom baseline truth. The below computation therefore may take a while to run and may use a large amount of memory. Ideally, if you can it is recommended you run these jobs on a cluster. However, you should be able to run this locally provided you keep `nsims` small and don't mind waiting a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 3 simulation instances\n",
    "sim2D(desInd, OutDir, nsim=3, mode='Tstat', REML=True)\n",
    "\n",
    "# List contents of output directory.\n",
    "os.listdir(OutDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running multiple simulations in parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned at the start of this document, the simulation functions for the Fisher Scoring methods have been designed with cluster computation in mind. The file `LMMPaperSim.sh` contains bash commands and commented suggestions for how to run these functions on a cluster. As cluster set-ups vary notably from lab to lab we cannot provide exact commands for cluster submission but hope that this notebook and the surrounding files should be comprehensive enough so that anyone who wishes to submit the code to a cluster can do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running `lmer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, we now run the same simulations in `lmer`. This is why we previously saved the `X`, `Y` and `Z` files for each simulation. To do this the `LMMPaperSim.r` code must be run in the programming language `R`. Before running this code, we suggest you first open the file to check that the input options (i.e. the simulation mode, the number of simulations the code thinks we have run, the design index,... etc.) match those used above. Once you have done this, you can either run the file manually or source it in the `R` command line using the below command (with the path changed appropriately)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`source('~/Path/To/Repository/LMMPaper/src/Simulations/LMMPaperSim.r')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once this has been done, you will find a column has been added to the results file for `lmer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the results file.\n",
    "results_table = pd.read_csv(os.path.join(OutDir,'Sim2_Design2_results.csv'),index_col=0)\n",
    "\n",
    "# Display results\n",
    "results_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The `R` code above must be run before moving onto the following sections of this notebook. This is as the following python code is expecting results from `lmer` to now be recorded in the results file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the simulations have been run, the results may be combined across simulations using the below function;\n",
    "\n",
    " - `tOutput`: This collates the T statistic, P value and degrees of freedom estimate output from the simulations.\n",
    " \n",
    "This function was used to obtain the data which produced the figure displayed in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-test output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `tOutput` calculates the T-test output for each simulation and stores the results in tables. The [pandas description](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html) of the tables are printed as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tOutput(desInd, OutDir, nsim=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code can be used to see which files have now been created. `tTable.csv` contains the T-statistics for each method in each simulation. `pTable.csv` contains the p values used for each method in each simulation. `dfTable.csv` contains the Satterthwaite degrees of freedom estimates from each simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List contents of output directory.\n",
    "glob.glob(os.path.join(OutDir,'*Table.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below one of the files, the table of Satterthwaite degrees of freedom estimates, is displayed. The row index corresponds to simulation number and the column index corresponds to the method used for parameter estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the results file.\n",
    "df_table = pd.read_csv(os.path.join(OutDir,'dfTable.csv'),index_col=0)\n",
    "\n",
    "# Display results\n",
    "df_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The boxplot display in the paper (Figure 1) was generated in `R` using the package `ggplot2`. The code used to do this can be found in `src/Simulations/Boxplots.r`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
